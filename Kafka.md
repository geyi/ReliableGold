在同一个topic下
- 无关的数据就分散到不同的分区里，以追求并发并行
- 有关的数据，一定要按原有顺序发送到同一个分区里

在Kafka中分区具有副本的概念。既然有副本，那么就可以有读写分离，但是读写分离会带来一致性问题。所以Kafka规定只能在主分区上进行W/R

Kafka的broker的partition保存了从producer发送来的数据 -> 数据可以被重复利用（数据的重复利用是站在group上的，但是group内要保证如下单一场景的描述）

在单一场景下，即便在追求性能使用多个consumer进行消费，但是一个partition不能由多个consumer消费。即：partition与consumer的对应关系只存在1:1及N:1的关系，不允许1:N的关系（无法保证顺序行）
